---
title:      "变积系数"
date:       2017-11-23
author:     "YU"
categories: [数学]
tags:
    - 数学
--- 

# 变积系数

前述内容应该参见几何变换和射影几何（一）。
现补充下述内容：
平面上的一个仿射点变换$\sigma$引起了平面的一个向量变换$\bar \sigma$
（指平面上所有向量组成的集合$\bar S$的变换）
$p_1'=Ap_1+A_0,p_2'=Ap_2+A_0$
$(p_1'-p_2')=A(p_1-p_2)$
这说明$\vec{P'Q'}$的坐标只跟$\sigma$和向量m有关，而与m的有向线段中的起点的选择无关，因此可以规定集合$\bar S$里的一个对应法则$\bar \sigma$,它把m对应到$\vec{P'Q'}$,即：
$$
\bar\sigma(\mathbf{m})=\bar\sigma(\vec{PQ})=\vec{P'Q'}
$$
由上述讨论知$\bar\sigma$是$\bar S$的一个变换。

## 仿射变换的变积系数

设在平面上规定了一个定向，它用单位法向量$e$代表，用$(a,b)$表示以a，b为邻边的并且边界的环行方向为a到b的旋转方向的定向平行四边形的定向面积，易知：
$$
a\times b=(a,b)e
$$
**定理** 设仿射变换$\tau$在仿射标架$I[O;e_1,e_2]$中的公式为
$$
\begin{pmatrix}
x' \\
y'
\end{pmatrix}=
\begin{pmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{pmatrix}
\begin{pmatrix}
x \\
y
\end{pmatrix}+
\begin{pmatrix}
a_1 \\
a_2
\end{pmatrix}
$$
对于任意不共线向量a，b设$\bar\tau(a)=a',\quad\bar\tau(b)=b'$,则有
$$
\frac{(a',b')}{(a,b)}=\begin{vmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{vmatrix}
$$
$proof.$
由于$\tau$是仿射变换，因此它把仿射标架I变成了仿射标架II，$\bar\tau$在I中的公式可算出$e_1'$的I坐标是$(a_{11},a_{21})'$,$e_2'$的I坐标是$(a_{12},a_{22}$
设a,b的I坐标分别为$(u_1,v_1),(u_2,v_2)$,则$a',b'$的II坐标分别为$(u_1,v_1),(u_2,v_2)$。在坐标系I中计算得：
$$
\begin{aligned}
a\times b=&(u_1e_1+v_1e_2)\times(u_2e_1+v_2e_2)\\
=&\begin{vmatrix}
u_1 & u_2 \\
v_1 & v_2
\end{vmatrix}(e_1\times e_2)
\end{aligned}
$$
因为$a\times b=(a,b)e,e_1\times e_2=(e_1,e_2)e$所以
$$
(a,b)=\begin{vmatrix}
u_1 & u_2 \\
v_1 & v_2
\end{vmatrix}(e_1,e_2)
$$
注意到此公式对平面上的任意向量a，b均成立，特别地，对于$e_1',e_2'$有
$$
(e_1',e_2')=\begin{vmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{vmatrix}(e_1,e_2)
$$
同理，在II中计算得：
$$
(a',b')=\begin{vmatrix}
u_1 & u_2 \\
v_1 & v_2
\end{vmatrix}(e_1',e_2')
$$
因此
$$
\frac{(a',b')}{(a,b)}=\frac{(e_1',e_2')}{(e_1,e_2)}=\begin{vmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{vmatrix}
$$
易知如果仿射变换$\tau$在仿射坐标系I中的公式的系数矩阵为A，那么$\tau$在仿射坐标系II中的公式的系数矩阵为$H^{-1}AH$,其中H是I到II的过渡矩阵。因为
$$
|H^{-1}AH|=|A|
$$
所以仿射变换$tau$的公式中的系数矩阵的行列式与仿射标架的选择无关。

仿射变换$\tau$的公式中的系数矩阵的行列式称为$\tau$的行列式记作$d_\tau$,仿射变换$\tau$按同一个比值$|d_\tau|$来改变平面上所有(有面积)的图形的面积，因此把$|d_\tau|$称为仿射变换$\tau$的变积系数。

## 一般情形下的变积系数

### 二维情形

设
$$
\begin{cases}
   x=\rho\cos\theta  \\
   y=\rho\sin\theta
\end{cases}
$$
我们把上式看做由直角坐标平面$\rho O\theta$到直角坐标平面$xOy$的一种变换，即对于$\rho O\theta$上的一点$M'(\rho,\theta)$通过变换变成了$xOy$平面上的一点$M(x,y)$,在两个平面各自限定的范围内，这种变换还是一一映射，

**定理**
$$
T:x=x(u,v),y=y(u,v)
$$
将平面$uOv$上的闭区域D'变为xOy上的D，且满足
1. $x(u,v),y(u,v)$在$D'$上具有一阶连续偏导数；
2. 在D'上的雅各比矩阵$J(u,v)=\frac{\partial(x,y)}{\partial(u,v)}\neq 0$
3. 变换$T:D'\to D$是一对一的，有
$$
dxdy=|J(u,v)|dudv
$$

### 一般情形
$$
\mathbf J = \begin{bmatrix}
    \dfrac{\partial \mathbf{f}}{\partial x_1} & \cdots & \dfrac{\partial \mathbf{f}}{\partial x_n} \end{bmatrix}
= \begin{bmatrix}
    \dfrac{\partial f_1}{\partial x_1} & \cdots & \dfrac{\partial f_1}{\partial x_n}\\
    \vdots & \ddots & \vdots\\
    \dfrac{\partial f_m}{\partial x_1} & \cdots & \dfrac{\partial f_m}{\partial x_n} \end{bmatrix}
$$

The Jacobian generalizes the gradient of a scalar (mathematics)|scalar-valued function of multiple variables, which itself generalizes the derivative of a scalar-valued function of a single variable. In other words, the Jacobian for a scalar-valued multivariate function is the gradient and that of a scalar-valued function of single variable is simply its derivative. The Jacobian can also be thought of as describing the amount of "stretching", "rotating" or "transforming" that a transformation imposes locally. For example, if $(x',y')=f(x,y)$is used to transform an image, the Jacobian $J_f(x,y)$ describes how the image in the neighborhood of $(x,y)$ is transformed.

![](https://upload.wikimedia.org/wikipedia/en/thumb/9/96/Jacobian_determinant_and_distortion.svg/600px-Jacobian_determinant_and_distortion.svg.png)

If a function is differentiable at a point, its derivative is given in coordinates by the Jacobian, but a function does not need to be differentiable for the Jacobian to be defined, since only the [[partial derivative]]s are required to exist.

If p is a point in $R^n$ and f is derivative at p, then its derivative is given by $J_f(p)$. In this case, the linear map described by $J_f(p)$ is the best linear approximation off near the point p, in the sense that

$$\mathbf f(\mathbf x) = \mathbf f(\mathbf p) + \mathbf J_{\mathbf f}(\mathbf p)(\mathbf x - \mathbf p) + o(\|\mathbf x - \mathbf p\|)$$

for x close top and where o is the Little-o_notation for$x\to p$ and $||x-p||$ is the Euclidean distance between x andp.
Compare this to a Taylor series for a scalar function of a scalar argument, truncated to first order:

$$ f(x) = f(p) + f'(p) (x - p) + o(x - p) .$$

In a sense, both the gradient and Jacobian are "derivative"—the former the first derivative of a ''scalar function'' of several variables, the latter the first derivative of a ''vector function'' of several variables.

The Jacobian of the gradient of a scalar function of several variables has a special name: the Hessian matrix, which in a sense is the "second derivative" of the function in question.

## 参考资料
1. 解析几何 丘维声
2. Jacobi Matirx,Wikipedia
